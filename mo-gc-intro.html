<!DOCTYPE html>
<html lang="en">
<head>
        <title>An Experiment in Garbage Collection</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css" />
        <link rel="stylesheet" href="/theme/css/main.css" />
</head>
<body>

    <div class="main-nav-container">

        <div class="pure-g">
            <div class="pure-u-1 pure-u-lg-2-3">
                <div class="main-nav">
                    <ul class="main-nav-list">
                        <li class="main-nav-item"><a href="/" class="pure-menu-link">TL;DR</a></li>

                        <li class="main-nav-item active"><a href="/category/rust.html" class="pure-menu-link">Rust</a></li>
                    </ul>
                </div>
             </div>

             <div class="pure-u-1 pure-u-lg-1-3"></div>
        </div>

    </div>


<div class="page-container">
    <div class="entry-content">
        <div class="post-meta pure-g">
            <div class="pure-u-3-4 meta-data">
                <a href="/category/rust.html" class="category">Rust</a><br />

                <a class="author" href="/author/peter-liniker.html">Peter Liniker</a>
                &mdash; <abbr title="2016-03-13T21:00:00-04:00">Sun 13 March 2016</abbr>
            </div>
        </div>
    </div>

    <div class="article-header-container">
        <div class="background-image-container">

            <div class="background-image-small">
                <div class="title-container">
                    <h1>An Experiment in Garbage Collection</h1>
                </div>
            </div>
        </div>
    </div>

    <div class="entry-content">
        <p><strong>Interim results for <a href="https://github.com/pliniker/mo-gc">mo-gc</a>, a garbage collector
written in Rust.</strong></p>
<blockquote>
<p>Mo-gc is an experiment in garbage collection written in the Rust programming language.</p>
<p>Instead of scanning the stack, the mutator writes reference count
increments and decrements to a journal. The journal is read concurrently by a garbage
collection thread that keeps a map of objects and their absolute reference counts. The object
map is divided into young and mature generations and collection is done with parallellized
mark and sweep phases.</p>
<p>The journal is a type of snapshot-at-beginning write barrier and this project
is an experiment in the feasibility, limitations and scalability of this approach.</p>
<p>A second aspect of the experiment is to gauge the possible performance of a GC in and for
Rust that does not depend on rustc, Rust runtime or LLVM awareness of a GC.</p>
</blockquote>
<h1>Contents</h1>
<ul>
<li><a href="#rt">Motivation: Hosting Languages</a></li>
<li><a href="#gcrust">Garbage Collection and Rust</a></li>
<li><a href="#inmo">Inside mo-gc</a></li>
<li><a href="#usemo">Using mo-gc</a></li>
<li><a href="#ds">Implementing Data Structures</a></li>
<li><a href="#res">Summary of Results</a></li>
<li><a href="#conc">Coherence</a></li>
<li><a href="#thro">Throughput</a></li>
<li><a href="#rem">Next Directions</a></li>
<li><a href="#read">Further Reading</a></li>
</ul>
<h3><a name="rt"></a>Motivation: Hosting Languages</h3>
<p>If a higher level programming language is not hosted in itself, there is a very high chance that
it is written in C or C++. By a degree of necessity, lower level interaction or optimized
extensions of those runtimes must also be in C or C++, perpetuating the pervasiveness of
these two languages.</p>
<p>Mo-gc is motivated by the safety benefits of Rust over C and C++ to explore a programming
language runtime written in Rust. Having familiar and attractive dynamic or scripting languages
written in Rust may lead to wider Rust adoption, spreading the safety.</p>
<p>A garbage collector is a fundamental requirement for most languages. It makes some sense to begin
there rather than deferring the problem of memory management.</p>
<h3><a name="gcrust"></a>Garbage Collection and Rust</h3>
<p>As <a href="https://github.com/pnkfelix">pnkfelix</a> has <a href="http://blog.pnkfx.org/blog/2015/10/27/gc-and-rust-part-0-how-does-gc-work/">already</a> <a href="http://blog.pnkfx.org/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/">written</a> <a href="http://blog.pnkfx.org/blog/2016/01/01/gc-and-rust-part-2-roots-of-the-problem/">a thorough</a> introduction to the
challenges involved in integrating a garbage collector with Rust, I will not repeat what I
cannot improve on. The primary barrier to writing an effective garbage collector in and/or for Rust
is the current lack of Rust compiler awareness of garbage collection needs. It is understood that
this is in the research phase and that some proposals may be announced <a href="http://blog.rust-lang.org/2015/08/14/Next-year.html">this year</a>.</p>
<p>Partially because it is not available but also somewhat to keep a runtime as
unobtrusive and as lightweight as possible, mo-gc chooses to avoid the use of GC support. Most
notably this means avoiding the standard technique of stop-the-world stack-scanning.</p>
<p>On the one hand, we have decided not to be reliant on non-existent compiler GC support.</p>
<p>On the other hand, we do not necessarily want memory management that is too distant from the host
language. <a href="http://fitzgeraldnick.com/weblog/60/">Oxischeme</a> is hosted in Rust and has an <a href="https://github.com/fitzgen">arena based mark-and-sweep</a> garbage
collector, with different arenas for different object types. This makes it suitable for the
runtime it is integrated with, but far less ergonomic for more general use in Rust.</p>
<p>As a consequence, mo-gc is analagous to <a href="https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/">SpiderMonkey's relationship with Servo</a>, in that
smart pointers are required to root and unroot objects. Some ergonomics are sacrificed here, but
the tradeoff is established and currently accepted in Servo. A further benefit is that
GC-managed objects and pure Rust compile-time managed objects are clearly delineated.</p>
<h4>Tracing Concurrently</h4>
<p>Because we do not have type maps to rely on, every object that wishes to participate
in being GC managed must implement a trait:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">unsafe</span><span class="w"> </span><span class="k">trait</span><span class="w"> </span><span class="n">Trace</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="n">traversible</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">bool</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="n">trace</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">stack</span><span class="o">:</span><span class="w"> </span><span class="o">&amp;</span><span class="k">mut</span><span class="w"> </span><span class="n">TraceStack</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</td></tr></table>

<p>The GC thread does not know the absolute type of every object it is managing so these methods,
when called from the GC thread, are inevitably virtual function calls.</p>
<p>The <code>traversible()</code> method must return <code>true</code> if the object may refer to other GC-managed objects.
This method is called from the mutator and the value passed through the journal to the GC. This
is an optimization that allows the GC to avoid making the call to <code>trace()</code> if the <code>TRAVERSIBLE</code>
bit is not set, saving an unnecessary virtual function call. On the mutator side, since the type
is known at compile-time and the return value of <code>traversible()</code> is a literal, the function call
can be largely optimized away.</p>
<p>The <code>trace()</code> method takes a parameter of type <code>TraceStack</code> which, as its name implies, is the
stack of objects buffered for tracing (or the list of gray objects in a tri-color equivalent
scheme.) The <code>trace()</code> method should call <code>stack.push(object)</code> for every object that it refers to.</p>
<p>The implementation of <code>trace()</code>, since it is called from the GC thread concurrently with the
mutator running, must be thread safe. Any mechanism may be used, even locks if necessary.
Because the thread safeness cannot be guaranteed by the compiler, just as with the <code>Sync</code> trait
<code>Trace</code> is an unsafe trait.</p>
<h3><a name="inmo"></a>Inside mo-gc</h3>
<h4>The Journal</h4>
<p>The journal behaves as a non-blocking unbounded queue. It is implemented as an unbounded series
of one-shot single-writer SPSC buffers, making it very fast.</p>
<p>Testing on a Xeon E3-1271 gives a throughput of about 500 million two-word objects per second.</p>
<p>Reference count increments from the journal are read into a heap map while decrements are pushed
into a buffer to be applied after the current collection cycle is complete. This is what
fundamentally makes this GC design snapshot-at-beginning.</p>
<h4>The Heap Maps</h4>
<p>Each heap map - young and mature generation - is implemented using a bitmapped vector trie. This
gives access of <code>O(log 32)</code> on 32 bit systems and <code>O(log 64)</code> on 64 bit systems, though on 64 bit
systems the trie depth can be greater than on 32 bit systems.</p>
<p>This bitmapped trie can be sharded into sub-tries, each of which can be borrowed by a thread in
a scoped thread context. Each shard can be structurally mutated in parallel with the other shards.</p>
<h5>The Young Generation</h5>
<p>The young generation heap map doubles as the root set reference count map. Collecting the young
generation is done by sharding the map into at least as many parts as there are CPUs available
to parallelize tracing. Each shard is scanned for roots, which are non-zero reference counted
objects and all non-newly-allocated objects. They form the first set of gray objects, which are
traced to find more gray objects to add to the trace stack.</p>
<p>There are two distinct categories of objects in the young generation map: reference counted
mature objects and newly allocated objects. Only newly allocated object entries are candidates for
sweeping.</p>
<h5>Parallelism</h5>
<p>Each thread has it's own trace stack, minimizing synchronziation between threads, but making it
possible that two or more threads might attempt to trace the same object concurrently. That is
not inherently a problem.</p>
<p>Both marking and sweeping are multi-threaded, with work spread across all available CPUs by default.</p>
<p>For marking, the root set is sharded across a thread pool and the heap is concurrently marked,
while for sweeping, the heap is sharded across the thread pool with each shard being swept
concurrently with others.</p>
<h3><a name="usemo"></a>Using mo-gc</h3>
<p>Usage is superficially straightforward, excepting the coherence issues detailed later.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">extern</span><span class="w"> </span><span class="k">crate</span><span class="w"> </span><span class="n">mo_gc</span><span class="p">;</span><span class="w"></span>

<span class="kn">use</span><span class="w"> </span><span class="n">mo_gc</span><span class="o">::</span><span class="p">{</span><span class="n">GcRoot</span><span class="p">,</span><span class="w"> </span><span class="n">GcThread</span><span class="p">};</span><span class="w"></span>


<span class="k">fn</span><span class="w"> </span><span class="n">app</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">something</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GcRoot</span><span class="o">::</span><span class="n">new</span><span class="p">(</span><span class="nb">String</span><span class="o">::</span><span class="n">from</span><span class="p">(</span><span class="s">&quot;look ma! I have no defined lifetime!&quot;</span><span class="p">));</span><span class="w"></span>
<span class="w">    </span><span class="n">println</span><span class="o">!</span><span class="p">(</span><span class="s">&quot;String says {}&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">something</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>


<span class="k">fn</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">gc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GcThread</span><span class="o">::</span><span class="n">spawn_gc</span><span class="p">();</span><span class="w"></span>

<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">handle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gc</span><span class="p">.</span><span class="n">spawn_app</span><span class="p">(</span><span class="o">||</span><span class="w"> </span><span class="n">app</span><span class="p">());</span><span class="w"></span>

<span class="w">    </span><span class="n">handle</span><span class="p">.</span><span class="n">join</span><span class="p">().</span><span class="n">expect</span><span class="p">(</span><span class="s">&quot;app thread failed&quot;</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">gc</span><span class="p">.</span><span class="n">join</span><span class="p">().</span><span class="n">expect</span><span class="p">(</span><span class="s">&quot;gc thread failed&quot;</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</td></tr></table>

<h3><a name="ds"></a>Implementing Data structures</h3>
<p>Because of coherence issues detailed later, it is not yet appropriate to experiment with complex
data structures.</p>
<h3><a name="res"></a>Summary of Results</h3>
<h4>Measures</h4>
<p>Points of general garbage collection interest are:</p>
<ul>
<li>maximum mutator latency</li>
<li>minimum mutator utilization</li>
<li>GC memory requirement overhead</li>
<li>GC CPU burden relative to mutator</li>
</ul>
<p>In the case of mo-gc, maximum latency is close to the speed of allocation. As to the other
measures, they have yet to be taken and in particular, MMU and GC CPU burden are highly
dependent on the use-case.</p>
<p>A brief list of test cases and their descriptions is given here:</p>
<table>
<thead>
<tr>
<th>Test</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>tight loop allocating 25,000,000 8-byte objects</td>
</tr>
<tr>
<td>2</td>
<td>as test 1 but with 50ms pause every 4096 allocations</td>
</tr>
</tbody>
</table>
<p>Some rudimentary results, conducted on an 8-core Xeon E3-1271, are listed below:</p>
<table>
<thead>
<tr>
<th>Test</th>
<th>Allocs/sec</th>
<th>Mut wall-clock</th>
<th>GC deallocs/sec</th>
<th>GC CPU time</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>22,400,000</td>
<td>1115ms</td>
<td>10,200,000</td>
<td>2460ms</td>
</tr>
<tr>
<td>2</td>
<td>81,000</td>
<td>30,800ms</td>
<td>2,000,000</td>
<td>1200ms</td>
</tr>
</tbody>
</table>
<p>In the first test case, the mutator gets near 100% of a CPU as the GC is not running on all eight
cores at all times.</p>
<p>The second test shows a GC performance of 20% that in the first test. This is due to the
lack of tuning of when a collection should occur. Currently a collection is made every time
the journal returns non-empty, but in test 2 the number of journal entries per collection
is low.</p>
<h4>Qualitative Summary of Performance</h4>
<ol>
<li>
<p>Since the journal is a form of write barrier, where every rooting, unrooting and new object must
   be journaled, it is undoubtable that this implementation is less efficient than an
   incremental garbage collector where a write barrier is also required, which in turn
   is less efficient than non-incremental stop-the-world where no write barrier is needed.</p>
</li>
<li>
<p>The journal itself is a success and appears to scale, at least on x86(32 and 64). Writing a
   two-word struct to the journal adds roughly 25% to the cost of allocating a 64 byte object on
   the heap.<br><br>
   Since Rust's borrow mechanism may be used to alleviate unnecessary root reference count
   adjustments (just as an <code>Rc&lt;T&gt;</code> may be borrowed rather than cloned) in real world applications it
   is possible that the journal write barrier cost may be ameliorated some.</p>
</li>
<li>
<p>The parallel mark and sweep phases and the journal itself are sufficiently performant that the
   throughput bottleneck in the system is very evident: <em>processing</em> the journal into the object map is
   currently single-threaded because insertion into the map is not concurrent.<br/><br/>
   With a mutator thread allocating new objects in a tight loop, the GC thread's throughput is about
   half the rate at which they are allocated.<br/><br/>
   If object map insertion could be done in parallel on multiple threads, throughput scalability
   would improve greatly.</p>
</li>
<li>
<p>The object map is implemented using a bitmapped trie with compressed nodes and a path cache.
   Indeces are the object addresses and they are mapped to metadata including the object reference
   count. This was the author's first Rust code and should be forgiven.<br/><br/>
   The use of the trie might also be improved on: while there is a trie path cache, on average,
   each object lookup requires multiple pointer indirections.</p>
</li>
<li>
<p>Mo-gc retains the default Rust allocator, jemalloc, rather than implementing its own allocator.
   The object map essentially duplicates jemalloc's internal radix trie, increasing the number of
   clock cycles for dropping dead objects. Maintaining a separate object map also increases memory
   requirements.</p>
</li>
<li>
<p>Coherence issues between the mutator and GC threads detailed in the next section.</p>
</li>
</ol>
<h3><a name="conc"></a>Coherence</h3>
<p>In brief, the limitations of the current implementation of the journal as a write barrier as
described below are the same set of problems that are overcome by an incremental garbage
collector's write barrier.</p>
<h4>Journal as Write Barrier</h4>
<p>There is a use-after-free condition in the current implementation where, during the mark phase of
collection, the mutator reads a pointer from the heap, roots it, and then overwrites the
heap location with a new pointer or null before the heap location has been traced. The object
pointed to has been rooted and a journal entry been written, but the mark phase is not reading
the journal at this point. The sweep phase will then drop the object leaving the mutator in
a use-after-free state.</p>
<p>This means that the mutator threads cannot currently use mo-gc in it's present
form as fully general purpose, or rather that data structures must be persistent or designed
to avoid this scenario.</p>
<p>The fix is not obvious. At first it may seem that we just need to read journal entries
that were written during the mark phase and trace those too. But we end up back where we started,
as that itself is a mark phase and we then need to repeat the operation potentially indefinitely.</p>
<p>The problem that must be solved looks like this:</p>
<ol>
<li>object <code>LittleCatA</code> contains a reference to <code>LittleCatB</code>, which in turn refers to <code>LittleCatC</code>
   all the way through in a linked list to <code>LittleCatZ</code></li>
<li>the mutator has rooted <code>LittleCatA</code></li>
<li>the GC enters the mark phase and begins tracing objects</li>
<li>before <code>LittleCatA</code> is traced, the pointer to <code>LittleCatB</code> is popped off and replaced with
   <code>null</code></li>
<li>the mutator roots <code>LittleCatB</code> by writing an entry to the journal</li>
<li>the GC traces <code>LittleCatA</code> and finds nothing inside</li>
<li>the GC enters the sweep phase, dropping <code>LittleCatB</code> all the way through <code>LittleCatZ</code></li>
</ol>
<p>This is essentially a similar type of problem that <a href="https://engineering.heroku.com/blogs/2015-02-04-incremental-gc/">incremental garbage collectors</a> solve with
tri-color marking and <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey/Internals/Garbage_collection">write barriers</a> on objects.</p>
<p>We need a synchronization point other than the reference count journal. A secondary write
barrier, a sequential store buffer, may fulfill this function. It may be necessary to make
writes to the SSB blocking while the mark phase is draining it.</p>
<p>This write barrier must send the pointer value that the mutator is about to overwrite to the SSB.</p>
<p>Additionally, a bit in the pointed-at object header might be set so that the mutator can avoid
the SSB overhead if it needs to send that object through the write barrier again. The sweep phase
would be responsible for resetting the flag - a gray flag.</p>
<h4>The Remembered Set</h4>
<p>If an object in the mature space is rooted and by way of indirection points at an object in the
young generation, that mature object root is insufficient in the current implementation to mark
the young object. The young object, if not reachable only in the young generation, will be
dropped.</p>
<p>A further write barrier feature must generate a reliable remembered set.</p>
<p>Without a custom allocator, this cannot be optimized into a card table.</p>
<p>With a custom allocator, the remembered set can be maintained per arena.</p>
<h3><a name="thro"></a>Throughput</h3>
<h4>Journal Processing</h4>
<p>The journal is currently processed in <code>YoungHeap::read_journals()</code> on a single thread only,
as the object map must be updated or inserted for each journal entry and insertion into
<code>bitmaptrie::Trie</code> cannot be done concurrently. This makes <code>Trie::set()</code> the single point of
GC throughput limitation, causing journal processing to consume most of the GC linear time.</p>
<p>If <code>Trie::set()</code> might be made thread-safe, throughput can be made to improve significantly and
the GC will begin to scale. This may be an unrealistic expectation for the current non-concurrent
trie implementation though.</p>
<p>A more approachable design may be to give each mutator thread its own young
generation object map. In this case the GC thread pool could process journals in parallel. However,
when tracing, each mutator thread's root set would be needed to trace all the other
object maps. This would allow a parallel approach but would be less efficient overall.</p>
<p>Giving each mutator thread its own young generation may pave the way to integrating a custom
allocator in a <a href="http://www.ccs.neu.edu/home/pnkfelix/thesis/klock11-diss.pdf">heap-partitioned</a> design, which will be discussed later.</p>
<p>Currently, two words are written to the journal for every entry. The second word is the vtable,
which is unnecessary overhead. The vtable could be added to an object header, making journal
entries only one word.</p>
<h4>A QoS Approach</h4>
<p>Most garbage collectors have to pause the mutator periodically, even if for only a few milliseconds.</p>
<p>If the GC is struggling to keep up with a mutator that is allocating large numbers of objects very
quickly, a quality of service style mechanism might be considered where the mutator's allocation
rate is throttled. This would hopefully be a last-resort option.</p>
<h4>Heap Map Optimizations</h4>
<p>The heap map, implemented with <code>bitmaptrie::Trie</code>, is at worst <code>O(log usize_width)</code> for lookup and
insertion. It is path cached to improve lookups based on the previous lookup rather than starting
at the root every time. Each node is also compressed, to minimize memory requirements.</p>
<p>It may be faster, though possibly more memory hungry, to maintain an array of reference counts and
a bitmap for mark flags of multiple objects in each leaf value. For example:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="k">struct</span><span class="w"> </span><span class="n">ObjectMetaArray</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">mark_flags</span><span class="o">:</span><span class="w"> </span><span class="n">BitField</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"></span>
<span class="w">    </span><span class="n">refcounts</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="kt">u32</span><span class="p">;</span><span class="w"> </span><span class="n">N</span><span class="p">],</span><span class="w"></span>
<span class="w">    </span><span class="n">vtables</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="kt">usize</span><span class="p">;</span><span class="w"> </span><span class="n">N</span><span class="p">],</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</td></tr></table>

<p>where <code>N</code> is a number of word-aligned addresses mapped to the array.  This would reduce trie
pointer hops, making insertion and iteration faster, but would increase memory use due to the
array being uncompressed.</p>
<p>Alternatively, the bitmapped trie might be replaced with a data structure more typical for this
purpose: a radix trie. It is not clear what magnitude of potential speedup is available here.</p>
<h4>Custom Allocator</h4>
<p>As mentioned in the section <em>Journal Processing</em>, this overall architecture may be
conducive to a partitioned-heap allocator and a <a href="http://www.ccs.neu.edu/home/pnkfelix/thesis/klock11-diss.pdf">corresponding collection approach</a>.</p>
<p>The possible advantages could be:</p>
<ul>
<li>
<p>Rotating journal buffers is already analagous to rotating heap partitions. Integrating the
  journal with a partitioned-heap allocation buffer per mutator thread may increase the efficiency
  both on the mutator and the GC thread sides.</p>
</li>
<li>
<p>Sweeping only allocation buffers that are not being allocated to by a mutator would reduce thread
  contention: the current implementation on top of mo-gc can create contention between the sweep
  phase and the mutator when the mutator is allocating and the sweeper is dropping.</p>
</li>
</ul>
<p>The downside of such an allocator is that since we cannot do heap compaction we will have to
take fragmentation into account when considering total memory use.</p>
<h3><a name"rem"></a>Next Directions</h3>
<p>The coherency and throughput issues make the current implementation impractical for use and must
be addressed.</p>
<p>The summary of options to investigate is:</p>
<ul>
<li>Partitioned heap: arena allocator with per-arena sequential store buffers; per-arena journals?</li>
<li>Mark one arena at a time; mark is complete when tracing roots is complete and SSB is empty.</li>
<li>Journal efficiency: one word per entry instead of two, move vtable to object header.</li>
<li>Explore alternatives to bitmaptrie for root set: a random-access heap data structure? Rust's
  BTreeMap?</li>
</ul>
<h1><a name="read"></a>Further Reading</h1>
<ul>
<li><a href="http://www.cs.virginia.edu/~cs415/reading/bacon-garbage.pdf">Bacon2004</a> Bacon et al, A Unified Theory of Garbage Collection</li>
<li><a href="http://www.hboehm.info/gc/tree.html">bdwgc</a> Boehm-Demers-Weiser GC, Two-Level Tree Structure for Fast Pointer Lookup</li>
<li><a href="http://www.ccs.neu.edu/home/pnkfelix/thesis/klock11-diss.pdf">Klock2011</a> Felix S Klock II, Scalable Garbage Collection via Remembered Set
  Summarization and Refinement</li>
<li><a href="http://fitzgeraldnick.com/weblog/60/">Oxischeme</a> Nick Fitzgerald, Memory Management in Oxischeme</li>
<li><a href="http://blog.rust-lang.org/2015/08/14/Next-year.html">Rust blog</a> Rust in 2016</li>
<li><a href="https://blog.mozilla.org/research/2014/08/26/javascript-servos-only-garbage-collector/">Servo</a> Servo blog, JavaScript: Servoâ€™s only garbage collector</li>
</ul>
    </div>

    <footer>
        <div class="tags">
            <a href="/tag/mo-gc.html">mo-gc</a>
            <a href="/tag/rust.html">rust</a>
            <a href="/tag/gc.html">gc</a>
        </div>
        <div class="pure-g post-footer">
            <div class="pure-u-1 pure-u-md-1-2">
                <div class="pure-g poster-info">
                    <div class="pure-u">
                        <a href="/author/peter-liniker.html"><img src="" alt=""></a>
                    </div>
                    <div class="pure-u-3-4">
                        <h3 class="author-name"><a href="/author/peter-liniker.html">Peter Liniker</a></h3>
                        <p class="author-description">
                          If you think without writing, you only think you're thinking. - Leslie Lamport.
                        </p>
                    </div>
                </div>
            </div>



        </div>


    </footer>


</div>


</body>
</html>